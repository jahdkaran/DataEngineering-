{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-09-05 13:52:28--  https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0221EN-SkillsNetwork/labs/module%206/Lab%20-%20Extract%20Transform%20Load/data/datasource.zip\n",
      "Resolving cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)... 169.45.118.108\n",
      "Connecting to cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)|169.45.118.108|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4249 (4.1K) [application/zip]\n",
      "Saving to: ‘datasource.zip’\n",
      "\n",
      "datasource.zip      100%[===================>]   4.15K  --.-KB/s    in 0s      \n",
      "\n",
      "2024-09-05 13:52:32 (69.2 MB/s) - ‘datasource.zip’ saved [4249/4249]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0221EN-SkillsNetwork/labs/module%206/Lab%20-%20Extract%20Transform%20Load/data/datasource.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import glob \n",
    "import xml.etree.ElementTree as ET \n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_from_csv(file_to_process):\n",
    "    dataframe = pd.read_csv(file_to_process)\n",
    "    return dataframe\n",
    "\n",
    "def extract_from_json(file_to_process):\n",
    "    dataframe = pd.read_json(file_to_process)\n",
    "    return dataframe\n",
    "\n",
    "def extract_from_xml(file_to_process):\n",
    "    dataframe = pd.DataFrame(columns=[\"car_model\", \"year_of_manufacture\", \"price\", \"fuel\"])\n",
    "    tree = ET.parse(file_to_process)\n",
    "    root = tree.getroot()\n",
    "    for car in root:\n",
    "        car_model = car.find(\"car_model\").text\n",
    "        year_of_manufacture = car.find(\"year_of_manufacture\").text\n",
    "        price = car.find(\"price\").text\n",
    "        fuel = car.find(\"fuel\").text\n",
    "        dataframe = pd.concat([dataframe, pd.DataFrame({\"car_model\": [car_model], \"year_of_manufacture\": [year_of_manufacture], \"price\": [price], \"fuel\": [fuel]})], ignore_index=True)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(folder):\n",
    "    extracted_data = pd.DataFrame(columns=[\"car_model\", \"year_of_manufacture\", \"price\", \"fuel\"])\n",
    "\n",
    "    for file in glob.glob(folder + \"/*.csv\"):\n",
    "        extracted_data = pd.concat([extracted_data, extract_from_csv(file)], ignore_index=True)\n",
    "\n",
    "    for file in glob.glob(folder + \"/*.json\"):\n",
    "        extracted_data = pd.concat([extracted_data, extract_from_json(file)], ignore_index=True)\n",
    "\n",
    "    for file in glob.glob(folder + \"/*.xml\"):\n",
    "        extracted_data = pd.concat([extracted_data, extract_from_xml(file)], ignore_index=True)\n",
    "\n",
    "    return extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(data):\n",
    "    # tranform price and round to upto 2 decimal places\n",
    "    data[\"price\"] = data[\"price\"].transform(lambda x: round(float(x), 2))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(transform_data):\n",
    "    transform_data.to_csv(\"transformed_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log(message):\n",
    "    timestamp_format = '%Y-%h-%d-%H:%M:%S'\n",
    "    now = datetime.now()\n",
    "    timestamp = now.strftime(timestamp_format)\n",
    "    with open(\"logfile.txt\", \"a\") as file:\n",
    "        file.write(timestamp + ',' + message + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_161/3061653740.py:5: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  extracted_data = pd.concat([extracted_data, extract_from_csv(file)], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "log(\"ETL Job Started\")\n",
    "\n",
    "log(\"Extract phase Started\")\n",
    "extracted_data = extract(\"datasource\")\n",
    "log(\"Extract phase Ended\")\n",
    "\n",
    "log(\"Transform phase Started\")\n",
    "transformed_data = transform_data(extracted_data)\n",
    "log(\"Transform phase Ended\")\n",
    "\n",
    "log(\"Load phase Started\")\n",
    "load(transformed_data)\n",
    "\n",
    "log(\"Load phase Ended\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
